{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4fc29c0d30afb83",
   "metadata": {},
   "source": [
    "# ADA final exam (Fall 2023)\n",
    "\n",
    "This exam consists of 2 parts. Parts are independent from each other.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "\n",
    "\"Friends\" is an American television sitcom that originally aired on NBC from September 22, 1994, to May 6, 2004. Created by David Crane and Marta Kauffman, the show gained immense popularity and has since become a classic in the world of television. The series is set in New York City and revolves around a group of six friends: Ross Geller (David Schwimmer), Rachel Green (Jennifer Aniston), Monica Geller (Courteney Cox), Chandler Bing (Matthew Perry), Joey Tribbiani (Matt LeBlanc), and Phoebe Buffay (Lisa Kudrow). The show explores their personal and professional lives as they navigate the ups and downs of relationships, careers, and the challenges of adulthood.\n",
    "\n",
    "In this exam, we will use a dataset containing all the conversations that occurred over 10 seasons of Friends. We refer to each row in the dataset as an 'utterance.\" The data format of the dataset is as follows\n",
    "\n",
    "- id: `<str>`, the index of the utterance in the format sAA_eBB_cCC_uDDD, where AA is the season number, BB is the episode number, CC is the scene/conversation number, and DDD is the number of the utterance in the scene (e.g. s01_e18_c05_u021).\n",
    "- speaker: `<str>`, the speaker who made the utterance, e.g. Monica Geller\n",
    "- conversation_id: `<str>`, the id of the first utterance in the conversation this utterance belongs. We assume conversations begin at the start of a new scene.\n",
    "- reply_to: `<str>`, the id of the utterance to which this utterance replies. None if the utterance is the first in a conversation.\n",
    "- text: `<str>`, the textual content of the utterance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b039cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import some required libraries!\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be188a",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: The one where you find the protagonist (60 pts)\n",
    "\n",
    "A big debate among Friends fans is: who is the show's main character? In this task, your goal is to provide a data-driven answer to this question.\n",
    "\n",
    "\n",
    "--- \n",
    "\n",
    "**1.1 —** Load the data from the jsonl file `exam1.jsonl` into a pandas dataframe. Then\n",
    " \n",
    " A. Calculate and display the number of distinct speakers in the dataframe.\n",
    " \n",
    " B. Calculate and display the number of conversations (see `conversation_id`).\n",
    " \n",
    " C. Remove all utterances from the dataframe where the `speaker` is \"TRANSCRIPT_NOTE\" or \"#ALL#\". Print the number of rows in the dataframe.\n",
    " \n",
    " D. Create additional columns corresponding to the season (`season`, e.g., season 1 should contain `s01`) and the episode (`episode`, e.g., episode 5 of season 4 should contain `s04_e05`) of each utterance. Print the season and the episode associated with utterance `s10_e18_c11_u019`.\n",
    " \n",
    " E. Create an additional column corresponding to the length of each utterance in terms of the number of characters (`length`). Print the length associated with utterance `s10_e18_c11_u019`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d3bdc7",
   "metadata": {},
   "source": [
    "**1.2** Next, you conduct some basic analyses:\n",
    "\n",
    " A. With `statsmodels`, fit a linear regression `length ~ C(season, Treatment(reference=\"s01\"))`, where length is an integer and season is a categorical variable. Print the regression summary.\n",
    " \n",
    " B. /**Discuss:/** Considering the regression summary:\n",
    "   - What does the intercept in this regression represent? \n",
    "   - What does the coefficient `C(season, Treatment(reference=\"s01\"))[T.s09]` represent? \n",
    "   - Does the average utterance in season 9 contain significantly more characters than in season 1 at the 0.05 significance level? Justify with the regression summary **only**. \n",
    "   - Does the average utterance in season 10 contain significantly more characters than in season 1 at the 0.05 significance level? Justify with the regression summary  **only** .\n",
    "\n",
    " C. Argue visually (i.e., with a plot) that there are 6 main characters in the show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d95b8",
   "metadata": {},
   "source": [
    "The intercept in this regression represents the value of the output variable (i.e. length of uttered line) when all other independent variables (i.e. season identifier) are set to 0. Because we specified the reference to be season 1, the intercept corresponds to the average utterance length of season 1 lines.\n",
    "\n",
    "The coefficient `C(season, Treatment(reference='s01'))[T.s09]` represents by how much the average length of an utterance changes if the season number is 9 and no other number (theorectically, since in this context it is clear that if an utterance belongs to season 9 then it cannot belong to another)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb47cab",
   "metadata": {},
   "source": [
    "--- \n",
    "**1.3 —** Using `networkx` \n",
    "\n",
    "A. Create a `MultiDiGraph` (directed graph with self loops and parallel edges) where:\n",
    "- Each node $u$ is a character uniquely identified by the `speaker` field.\n",
    "- There is an edge between nodes $u$ and $v$ if $u$ replied to $v$. If an utterance (a row in the dataframe) is said in reply to nobody, then it will not correspond to an edge. Each edge should contain two attributes. Each edge should have two attributes: `season` and `episode`.\n",
    "\n",
    "B. Print the number of nodes and edges in your graph.\n",
    "\n",
    "C. **/Discuss:/** Instead of using multi-edges, what would be another way in which you could capture the number of replies associated with each node pair?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab3a277",
   "metadata": {},
   "source": [
    "Instead of creating a MultiDiGraph, one could simply create a DiGraph (i.e. don't allow multiple edges per node pair), and instead add a weight to the edge between two nodes to symbolise how many times one responds to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130a16f1",
   "metadata": {},
   "source": [
    "---\n",
    "With the graph ready, you set out to investigate who is the true protagonist of Friends.\n",
    "\n",
    "Ignore the graph you generated previously and instead use the graph provided in `exam2.graphml`. Note that this graph may be slightly different from what you generated, but treat it as the ground truth. We provide you with code to load the graph below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad04b50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee10e7",
   "metadata": {},
   "source": [
    "**1.4 —** Using the provided MultiDiGraph $G$:\n",
    "\n",
    "A. Calculate the out-degree of each node (also known as out-degree centrality). Please do not use the `nx.out_degree_centrality` function here, as it normalizes the degree. (E.g., if a node has 5 outgoing edges, it should have out-degree 5 according to your code.)\n",
    "\n",
    "B. Calculate the PageRank centrality of each node in $G$. Use the default parameters.\n",
    "\n",
    "C. Print both centrality metrics calculated above for the six main characters of Friends.\n",
    "\n",
    "D. **/Discuss:/** According to the metrics, who is the most important character in Friends?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8f283",
   "metadata": {},
   "source": [
    "According to the metrics, the protagonist seems to be Rachel, because she has the largest out-degree, meaning that she is the most likely to respond when in a conversation, and she has the highest PageRank centrality, meaning that she also is responded to alot (like a webpage with many incoming links)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9f1601",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1.5 —** **/True or false:/** Considering your answer in **1.4**, are the following statements true or false? Justify your answers. \n",
    "\n",
    "A. \"If we inverted all  edges in the graph such that an edge $(u,v)$ becomes an edge $(v,u)$, the PageRank centrality would remain unchanged.\"\n",
    "\n",
    "B. \"If we removed all outgoing edges from Rachel Green, her PageRank centrality would remain unchanged.\"\n",
    "\n",
    "C. \"If a new node was introduced in the graph, with 1,000 outgoing edges towards each other node, but no incoming edge, it would have the highest PageRank centrality.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd9cf2",
   "metadata": {},
   "source": [
    "A: False, because PageRank centrality depends on the number of incoming edges towards each node. Therefore, if we invert every edge, the in-degree becomes the out-degree, and the PageRank centrality will change.\n",
    "\n",
    "B: True, since PageRank depends on incoming links.\n",
    "\n",
    "C: False, for the same reson as B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e47355c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1.6 —** Next, you consider how these centrality metrics vary over the course of the seasons.\n",
    "\n",
    "A. Calculate the PageRank and out-degree centrality of the 6 main characters per episode, i.e., for each episode, create a graph containing only the utterances of that episode and calculate the PageRank centrality for this new graph. Print the PageRank and the out-degree of Rachel Green for the first episode of the first season.\n",
    "\n",
    "B. Considering the episode-level out-degree centrality of Phoebe Buffay in season 1 and in season 10, print the mean and the standard error of the mean.\n",
    "\n",
    "C. Create a single plot with 10 inches of width and 4 inches of height. The plot should contain two panels, containing the average PageRank centrality per season of Rachel Green and Ross Geller (Panel A), and the average out-degree per season of Rachel Green and Ross Geller (Panel B). Show 95% confidence intervals in your plot (calculated over the episodes in each season).\n",
    "\n",
    "D. **/Discuss:/** Does the plot support the hypothesis that Rachel was the show's protagonist in all 10 seasons? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0e5b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**1.7 —** **/True or false:/** Considering your answer in **1.6** are the following statements true or false? Justify your answer. \n",
    "\n",
    "\n",
    "A. \"In season 7, Rachel Green's episode-level PageRank and out-degree centrality are higher than Ross Geller's. This difference is statistically significant at the 0.05 significance level.\"\n",
    "\n",
    "B. \"Phoebe Buffay's out-degree grew between season 1 and season 10; this implies that other characters spoke less than her in season 10.\"\n",
    "\n",
    "C. \"Phoebe Buffay's PageRank was higher in season 10 than in season 1. This difference is statistically significant at the 0.05 significance level and suggests that the character gained importance over the course of the show.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7061c53",
   "metadata": {},
   "source": [
    "A. not answered\n",
    "\n",
    "B. False, it simply means that she replied to more people in season 10, we can not make any more assumptions on the number of times the other characters spoke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0618b",
   "metadata": {},
   "source": [
    "p > 0.05, so the null hypothesis 'The difference in mean PageRank from season 1 to 10 is statistically insignificant' cannot be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84866967",
   "metadata": {},
   "source": [
    "## Part 2: The one about text similarity (40 pts)\n",
    "\n",
    "Next, you investigate how unique characters are by analyzing what they said throughout the 10 seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a69b8",
   "metadata": {},
   "source": [
    "**2.1 —** Load the dataframe `exam3.jsonl`. This dataframe is similar to `exam1.jsonl`, except:\n",
    "\n",
    "- It has an additional column called `tokens`, containing a sentence list. Each sentence is another list composed of tokens, e.g.,\n",
    "`[['There', \"'s\", 'nothing', 'to', 'tell', '!'], ['He', \"'s\", 'just', 'some', 'guy', 'I', 'work', 'with', '!']]`.\n",
    "- It has an additional column called `episode` containing a unique episode identifier.\n",
    "- It only contains utterances by Phoebe, Rachel, Ross, Joey, Monica, or Chandler (the main characters).\n",
    " \n",
    "Given this dataframe, you will create an episode-level word-frequency matrix for Chandler Bing, one of the main characters.\n",
    "\n",
    "A. Create a list $L$ containing all distinct tokens uttered by Chandler Bing throughout the 10 seasons, sorted in ascending order. Print the 10 first and last elements of the list. \n",
    "\n",
    "B. Create a matrix $X$ with $m$ rows and $n$ columns, where: $n$ is the number of tokens in the list $L$ that you just created, and $m$ is the number of episodes (236). Each position $X_{i,j}$ in this matrix should contain the number of times the character uttered the word $j$ in episode $i$. Print how many times Chandler uttered the token `joey` in the first episode of the first season, as well as the shape of the matrix $X$.\n",
    "\n",
    "C. Transform the matrix $X$ into a TF-IDF matrix $T$, combining the following formula (as seen in class):\n",
    "\n",
    "$$\\text{TF}(i,j) = \\text{number of times the $j$-th word occurs in the $i$-th episode}$$\n",
    "\n",
    "$$\\text{IDF}(j) =  \\log \\frac{\\text{number of episodes}}{\\text{number of episodes in which the $j$-th word occurs}}$$\n",
    "\n",
    "Print the value in the TF-IDF matrix corresponding to Chandler's utterance of the token `joey` in the first episode of the first season.\n",
    "\n",
    "D. **/Discuss:/** Some of the tokens (e.g., `joey`) reference other characters. How may these tokens help a classifier predict which character uttered a sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d611de93",
   "metadata": {},
   "source": [
    "(Questions B, C, not answered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dc10c",
   "metadata": {},
   "source": [
    "D. One could use the fact that some character names are spoken to predict which character said which sentence: for instance, if the token 'joey' is uttered and Ross is the one who replies most to Joey, then it is likely that Ross spoke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b691ae5",
   "metadata": {},
   "source": [
    "---\n",
    "For the remainder of the task, you will use the TF-IDF matrix that we compute below. Note:\n",
    "- This matrix was calculated in a slightly different way: it considers only the 1000 tokens with the highest term frequency.\n",
    "- We provide three useful variables below (`X`, `y`, and `df_tfidf`). \n",
    "    - `X` is a matrix containing the TF-IDF values for the top 1000 tokens, where each row corresponds to a character in an episode. \n",
    "    - `y` indicates which character is responsible for the utterance. Each character has a corresponding number, e.g., 2 for Monica Geller; see dictionary below. \n",
    "    - `df_tfidf` is a dataframe combining `X` with other episode and utterance-level metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f01045",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6b6f1",
   "metadata": {},
   "source": [
    "**2.2 —** To compare characters, carry out a classification task. Train a decision tree classifier to predict which main character uttered a sentence..\n",
    "\n",
    "A. Split the dataset into training and test sets using sklearn `sklearn.model_selection.train_test_split` using parameters `test_size=0.3` and `random_state=42`, and using the default values for all other parameters.\n",
    "\n",
    "B. Train a decision tree classifier (`sklearn.tree.DecisionTreeClassifier`) using `random_state=42`, leaving all other parameters as their default.\n",
    "\n",
    "C. Compute the accuracy of your classifier and of a random baseline, i.e., a classifier that predicts a character uniformly at random. **/Discuss:/** Compare the two accuracies.\n",
    "\n",
    "\n",
    "D. Compute the confusion matrix of your classifier using `sklearn.metrics.confusion_matrix`. Normalize the confusion matrix such that all cells sum to 1.\n",
    "\n",
    "E. Plot an appropriate graphical representation of the confusion matrix.\n",
    "\n",
    "F. **/Discuss:/** Analyzing the confusion matrix, discuss:\n",
    "   - Which character is most distinct in the way they talk?\n",
    "   - Which two characters are the most similar in the way they talk?\n",
    "   - Which two characters are the least similar in the way they talk?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a529f4",
   "metadata": {},
   "source": [
    "The accuracy for the random prediction is around 1/6, which is the theoretical value for a random prediciton of a 6-class classification. The DTC yielded a slightly better result, with around 24% of the predictions being correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ceb89a",
   "metadata": {},
   "source": [
    "The character with index 2 (i.e. Monica) is the most recognisable by her speech, because she is the character that was the best predicted using the decision tree classifier (white square with value 0.085 in the heatmap).\n",
    "\n",
    "The characters who talk the most similarly are the ones who were often wrongly classified: on the heatmap one can see that Monica's lines were often classified to be Chandler's (index [0,2] in the heatmap with value 0.06), meaning that their speech was often seen as similar by the classifier.\n",
    "\n",
    "On the other hand, by looking at index [0,3] with value 0, one could conclude that Monica and Phoebe have the least similar in the way they talk because Monica's lines were never interpreted as one of Phoebe's by the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a158a88",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**2.3 —** **/Discuss:/** Last, you discuss the results obtained in **2.2** with a friend, who asks you some thought-provoking questions.\n",
    "\n",
    "A. Your friend proposes that you should create a measure of similarity between two characters in a given episode in a more direct way than what you've done in **2.2**.  Propose (but do not implement) said similarity metric.\n",
    "\n",
    "B. Your friend also suggests that your analysis might not truly capture how two characters differ. According to her, if people are in the same conversation, they might speak similarly simply because they are in the same social context. Propose (but do not implement) a way of creating a dataset where this confounder does not exist.\n",
    "\n",
    "C. Last, your friend complains about how you present your (normalized) confusion matrix. According to her, from reading the cells alone, it is unclear if the fraction of occurrences is higher or lower than what a random classifier would yield. Propose (but do not implement) a way of modifying the confusion matrix to address her concern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea23a942",
   "metadata": {},
   "source": [
    "A. One could figure out, for each episode, the number of times that each character has replied to each other character, in order to figure out who is the most likely to entertain a conversation with whom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5768387b",
   "metadata": {},
   "source": [
    "B. In order to avoid the confounder of conversation similarity, one could perform a one-to-one matching between all groups of lines: the goal would be to make sure that every line uttered by one character is matched with another from every other character, and whose conversation identifier is the same. That way, the effect of the conversation context on all groups will be the same, and the potential confounding will disappear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f72f454",
   "metadata": {},
   "source": [
    "C. One way to illustrate clearly whether the fraction of occurences is higher or lower than the random classification for each cell, would be to divide all values by the values of the confusion matrix for the random classifier. If all values sum to 1 and there are 36 equal values, then all values of the random confusion matrix should be 1/36. My friend could then see if the ratio is larger or smaller than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c65d90",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
